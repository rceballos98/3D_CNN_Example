{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jupyter notebook --NotebookApp.kernel_spec_manager_class='environment_kernels.EnvironmentKernelSpecManager'\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Our application logic will be added here\n",
    "\n",
    "import math\n",
    "import sys, traceback\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data generating script\n",
    "def place_cube(matrix, origin, r):\n",
    "\t#dim = matrix.shape()\n",
    "\tmatrix[\n",
    "\torigin[0]-r:origin[0]+r,\n",
    "\torigin[1]-r:origin[1]+r,\n",
    "\torigin[2]-r:origin[2]+r,\n",
    "\t] = 1\n",
    "\treturn matrix\n",
    "\n",
    "def dist(x, y):\n",
    "\treturn math.sqrt(\n",
    "\t\t(x[0]-y[0])**2+\n",
    "\t\t(x[1]-y[1])**2+\n",
    "\t\t(x[2]-y[2])**2\n",
    "\t\t)\n",
    "\n",
    "def place_sphere(matrix, origin, r):\n",
    "\tfor index, x in np.ndenumerate(matrix):\n",
    "\t    if dist(index, origin) <= r:\n",
    "\t    \tmatrix[index] = 1\n",
    "\treturn matrix\n",
    "\n",
    "def random_shapes(m_size,num):\n",
    "    shapes = np.zeros((num,m_size,m_size,m_size))\n",
    "    shape_types = np.random.randint(low = 0,high = 2,size= num)\n",
    "    \n",
    "    for i in range(num):\n",
    "        if(i%(num/20) == 0):print(i/num)\n",
    "        r = np.random.randint(low = 3,high = np.floor(m_size/2-1))\n",
    "        org = np.random.randint(low = r + 1,high = m_size - r - 1, size = 3)\n",
    "        if shape_types[i] == 0:\n",
    "            shapes[i,:,:,:] = place_cube(shapes[i,:,:,:],org,r)\n",
    "        elif shape_types[i] == 1:\n",
    "            shapes[i,:,:,:] = place_sphere(shapes[i,:,:,:],org,r)\n",
    "            \n",
    "    return shapes, shape_types\n",
    "        \n",
    "\n",
    "def matching_shapes(m_size, num):\n",
    "\tcubes = np.zeros((m_size,m_size,m_size,num))\n",
    "\tspheres = np.zeros((m_size,m_size,m_size,num))\n",
    "\tfor i in range(num):\n",
    "\t\tr = np.random.randint(low = 3,high = np.floor(m_size/2-1))\n",
    "\t\torg = np.random.randint(low = r + 1,high = m_size - r - 1, size = 3)\n",
    "\t\tcubes[:,:,:,i] = place_cube(cubes[:,:,:,i],org,r)\n",
    "\t\tspheres[:,:,:,i] = place_sphere(spheres[:,:,:,i],org,r)\n",
    "\treturn cubes, spheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FC_SIZE = 1024\n",
    "DTYPE = tf.float32\n",
    "\n",
    "\n",
    "def _weight_variable(name, shape):\n",
    "    return tf.get_variable(name, shape, DTYPE, tf.truncated_normal_initializer(stddev=0.1))\n",
    "\n",
    "\n",
    "def _bias_variable(name, shape):\n",
    "    return tf.get_variable(name, shape, DTYPE, tf.constant_initializer(0.1, dtype=DTYPE))\n",
    "\n",
    "def inference(features):\n",
    "     # Input Layer\n",
    "    # input_layer = tf.reshape(features, [-1, 28, 28, 1])\n",
    "    prev_layer = features\n",
    "    num_props = 1\n",
    "    num_classes = 2\n",
    "    \n",
    "    in_filters = num_props\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        out_filters = 16\n",
    "        kernel = _weight_variable('weights', [5, 5, 5, in_filters, out_filters])\n",
    "        conv = tf.nn.conv3d(prev_layer, kernel, [1, 1, 1, 1, 1], padding='SAME')\n",
    "        biases = _bias_variable('biases', [out_filters])\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(bias, name=scope.name)\n",
    "\n",
    "        prev_layer = conv1\n",
    "        in_filters = out_filters\n",
    "\n",
    "    pool1 = tf.nn.max_pool3d(prev_layer, ksize=[1, 3, 3, 3, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n",
    "    norm1 = pool1  # tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta = 0.75, name='norm1')\n",
    "\n",
    "    prev_layer = norm1\n",
    "\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        out_filters = 32\n",
    "        kernel = _weight_variable('weights', [5, 5, 5, in_filters, out_filters])\n",
    "        conv = tf.nn.conv3d(prev_layer, kernel, [1, 1, 1, 1, 1], padding='SAME')\n",
    "        biases = _bias_variable('biases', [out_filters])\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(bias, name=scope.name)\n",
    "\n",
    "        prev_layer = conv2\n",
    "        in_filters = out_filters\n",
    "\n",
    "    # normalize prev_layer here\n",
    "    prev_layer = tf.nn.max_pool3d(prev_layer, ksize=[1, 3, 3, 3, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    with tf.variable_scope('conv3_1') as scope:\n",
    "        out_filters = 64\n",
    "        kernel = _weight_variable('weights', [5, 5, 5, in_filters, out_filters])\n",
    "        conv = tf.nn.conv3d(prev_layer, kernel, [1, 1, 1, 1, 1], padding='SAME')\n",
    "        biases = _bias_variable('biases', [out_filters])\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        prev_layer = tf.nn.relu(bias, name=scope.name)\n",
    "        in_filters = out_filters\n",
    "\n",
    "    with tf.variable_scope('conv3_2') as scope:\n",
    "        out_filters = 64\n",
    "        kernel = _weight_variable('weights', [5, 5, 5, in_filters, out_filters])\n",
    "        conv = tf.nn.conv3d(prev_layer, kernel, [1, 1, 1, 1, 1], padding='SAME')\n",
    "        biases = _bias_variable('biases', [out_filters])\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        prev_layer = tf.nn.relu(bias, name=scope.name)\n",
    "        in_filters = out_filters\n",
    "\n",
    "    with tf.variable_scope('conv3_3') as scope:\n",
    "        out_filters = 32\n",
    "        kernel = _weight_variable('weights', [5, 5, 5, in_filters, out_filters])\n",
    "        conv = tf.nn.conv3d(prev_layer, kernel, [1, 1, 1, 1, 1], padding='SAME')\n",
    "        biases = _bias_variable('biases', [out_filters])\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        prev_layer = tf.nn.relu(bias, name=scope.name)\n",
    "        in_filters = out_filters\n",
    "\n",
    "    # normalize prev_layer here\n",
    "    prev_layer = tf.nn.max_pool3d(prev_layer, ksize=[1, 3, 3, 3, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "    with tf.variable_scope('local3') as scope:\n",
    "        dim = np.prod(prev_layer.get_shape().as_list()[1:])\n",
    "        prev_layer_flat = tf.reshape(prev_layer, [-1, dim])\n",
    "        weights = _weight_variable('weights', [dim, FC_SIZE])\n",
    "        biases = _bias_variable('biases', [FC_SIZE])\n",
    "        local3 = tf.nn.relu(tf.matmul(prev_layer_flat, weights) + biases, name=scope.name)\n",
    "\n",
    "    prev_layer = local3\n",
    "\n",
    "    with tf.variable_scope('local4') as scope:\n",
    "        dim = np.prod(prev_layer.get_shape().as_list()[1:])\n",
    "        prev_layer_flat = tf.reshape(prev_layer, [-1, dim])\n",
    "        weights = _weight_variable('weights', [dim, FC_SIZE])\n",
    "        biases = _bias_variable('biases', [FC_SIZE])\n",
    "        local4 = tf.nn.relu(tf.matmul(prev_layer_flat, weights) + biases, name=scope.name)\n",
    "\n",
    "    prev_layer = local4\n",
    "\n",
    "    with tf.variable_scope('softmax_linear') as scope:\n",
    "        dim = np.prod(prev_layer.get_shape().as_list()[1:])\n",
    "        weights = _weight_variable('weights', [dim, num_classes])\n",
    "        biases = _bias_variable('biases', [num_classes])\n",
    "        softmax_linear = tf.add(tf.matmul(prev_layer, weights), biases, name=scope.name)\n",
    "\n",
    "    return softmax_linear\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  #\"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "\n",
    "    #input_layer = tf.reshape(features, [-1, 28, 28, 1])\n",
    "\n",
    "  # Logits Layer\n",
    "    logits = inference(features)\n",
    "\n",
    "    loss = None\n",
    "    train_op = None\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    if mode != learn.ModeKeys.INFER:\n",
    "        onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=2)\n",
    "        loss = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == learn.ModeKeys.TRAIN:\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=0.001,\n",
    "            optimizer=\"SGD\")\n",
    "\n",
    "  # Generate Predictions\n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(\n",
    "          input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(\n",
    "          logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "  # Return a ModelFnOps object\n",
    "    return model_fn_lib.ModelFnOps(\n",
    "        mode=mode, predictions=predictions, loss=loss, train_op=train_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_channel(data):\n",
    "    return np.expand_dims(data, axis = data.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(unused_argv):\n",
    "    # Load training and eval data\n",
    "#     mnist = learn.datasets.load_dataset(\"mnist\")\n",
    "#     train_data = mnist.train.images # Returns np.array\n",
    "#     train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "#     eval_data = mnist.test.images # Returns np.array\n",
    "#     eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "    tf.logging.info('loading data...')\n",
    "    train_data = add_channel(np.load('rand_shapes_data_small.npy'))\n",
    "    train_labels = add_channel(np.load('rand_shapes_labels_small.npy'))\n",
    "    \n",
    "    eval_data = add_channel(np.load('rand_shapes_data_test.npy'))\n",
    "    eval_labels = add_channel(np.load('rand_shapes_labels_test.npy'))\n",
    "    tf.logging.info('DONE')\n",
    "    \n",
    "    shapes_classifier = learn.SKCompat(learn.Estimator(\n",
    "      model_fn=cnn_model_fn, model_dir=\"shapes_convnet_model\"))\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "        # Train the model\n",
    "    shapes_classifier.fit(\n",
    "        x=train_data,\n",
    "        y=train_labels,\n",
    "        batch_size=10,\n",
    "        steps=100,\n",
    "        monitors=[logging_hook])\n",
    "    \n",
    "        # Configure the accuracy metric for evaluation\n",
    "    metrics = {\n",
    "        \"accuracy\":\n",
    "            learn.MetricSpec(\n",
    "                metric_fn=tf.metrics.accuracy, prediction_key=\"classes\"),\n",
    "    }\n",
    "    \n",
    "    # Evaluate the model and print results\n",
    "    eval_results = shapes_classifier.score(\n",
    "        x=eval_data, y=eval_labels, metrics=metrics)\n",
    "    print(eval_results)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loading data...\n",
      "INFO:tensorflow DONE\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12c5e0ad0>, '_model_dir': 'shapes_convnet_model', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into shapes_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 832.522, step = 1\n",
      "INFO:tensorflow:probabilities = [[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n",
      "ERROR:tensorflow:Model diverged with loss = NaN.\n",
      "Exception traceback:\n",
      "------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-76-a66c4a8b827d>\", line 2, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/Users/rodrigo/miniconda3/envs/condaEnvPy2TF1.2/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n",
      "    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n",
      "  File \"<ipython-input-75-49cfa40a503e>\", line 31, in main\n",
      "    monitors=[logging_hook])\n",
      "  File \"/Users/rodrigo/miniconda3/envs/condaEnvPy2TF1.2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1350, in fit\n",
      "    monitors=all_monitors)\n",
      "  File \"/Users/rodrigo/miniconda3/envs/condaEnvPy2TF1.2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 289, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/rodrigo/miniconda3/envs/condaEnvPy2TF1.2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 455, in fit\n",
      "    loss = self._train_model(input_fn=input_fn, hooks=hooks)\n",
      "  File \"/Users/rodrigo/miniconda3/envs/condaEnvPy2TF1.2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1007, in _train_model\n",
      "    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])\n",
      "  File \"/Users/rodrigo/miniconda3/envs/condaEnvPy2TF1.2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 505, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/Users/rodrigo/miniconda3/envs/condaEnvPy2TF1.2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 842, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/Users/rodrigo/miniconda3/envs/condaEnvPy2TF1.2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 798, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/Users/rodrigo/miniconda3/envs/condaEnvPy2TF1.2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 960, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/Users/rodrigo/miniconda3/envs/condaEnvPy2TF1.2/lib/python2.7/site-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 477, in after_run\n",
      "    raise NanLossDuringTrainingError\n",
      "NanLossDuringTrainingError: NaN loss during training.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.app.run()\n",
    "except:\n",
    "    print(\"Exception traceback:\")\n",
    "    print('-'*60)\n",
    "    traceback.print_exc(file=sys.stdout)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data, labels = random_shapes(32,2000)\n",
    "#Binary data\n",
    "np.save('rand_shapes_data_small.npy', data.astype(np.float32))\n",
    "np.save('rand_shapes_labels_small.npy', labels.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "0.35\n",
      "0.4\n",
      "0.45\n",
      "0.5\n",
      "0.55\n",
      "0.6\n",
      "0.65\n",
      "0.7\n",
      "0.75\n",
      "0.8\n",
      "0.85\n",
      "0.9\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "data, labels = random_shapes(32, 500)\n",
    "#Binary data\n",
    "np.save('rand_shapes_data_test.npy', data.astype(np.float32))\n",
    "np.save('rand_shapes_labels_test.npy', labels.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 32, 32, 32, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = add_channel(data)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:condaEnvPy2TF1.2]",
   "language": "python",
   "name": "conda-env-condaEnvPy2TF1.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
